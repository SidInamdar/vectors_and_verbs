<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Tech on Vectors &amp; Verbs</title>
    <link>http://localhost:1313/categories/tech/</link>
    <description>Recent content in Tech on Vectors &amp; Verbs</description>
    <generator>Hugo -- 0.154.2</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Jan 2026 00:23:31 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The DNA of Language: A Deep Dive into LLM Tokenization concepts</title>
      <link>http://localhost:1313/posts/the-dna-of-language/</link>
      <pubDate>Mon, 05 Jan 2026 00:23:31 +0530</pubDate>
      <guid>http://localhost:1313/posts/the-dna-of-language/</guid>
      <description>&lt;p&gt;Imagine you have to build a house. You cannot build a stable house only with massive boulders as walls (too big) or one cannot build a house only with tiny pebbles (too small). We need exactly the right sized bricks. Same analogy applies for linguistics. We need to figure out strategies to break down petabytes of data into usable atomic chunks.&lt;/p&gt;
&lt;p&gt;The the context of Large Language Models (LLMs), these bricks are called tokens. Tokens enable us to view a sizable amount of fluid language data into discrete mathematical language which machines can process. It is the invisible filter in the heart of LLMs where every prompt is passed and every response is born. Let&amp;rsquo;s dive into the most popular tokenization strategies used in LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Post</title>
      <link>http://localhost:1313/posts/first-post/</link>
      <pubDate>Sun, 04 Jan 2026 09:00:00 +0530</pubDate>
      <guid>http://localhost:1313/posts/first-post/</guid>
      <description>&lt;h2 id=&#34;welcome-to-vectors--verbs&#34;&gt;Welcome to Vectors &amp;amp; Verbs&lt;/h2&gt;
&lt;p&gt;This is a demo post to verify the PaperMod theme setup.&lt;/p&gt;
&lt;h3 id=&#34;features-of-this-theme&#34;&gt;Features of this theme:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Clean and minimal design&lt;/li&gt;
&lt;li&gt;Dark mode support&lt;/li&gt;
&lt;li&gt;Fast loading speed&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;hello_world&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Hello, Hugo!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Stay tuned for more updates!&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
